{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cec4b17-edae-4852-897c-3a27a21b87c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fb57c5-e3cd-49f2-9a88-a3c3bd52df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecbda8-e2f7-4bc6-931a-3b902b23cf6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e5d5c-0e24-4eaf-97a5-8643727fe906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"Explode\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1fc53-6f47-4676-87d9-39c48eb99ae9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea4144-2f49-490f-98f0-e194de7b03b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ddba7f-dc1f-4221-ae37-85cfe8cb89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- subjects: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n",
      "+-------+-----------------------------------+\n",
      "|name   |subjects                           |\n",
      "+-------+-----------------------------------+\n",
      "|James  |[[Java, Scala, C++], [Spark, Java]]|\n",
      "|Michael|[[Spark, Java, C++], [Spark, Java]]|\n",
      "|Robert |[[CSharp, VB], [Spark, Python]]    |\n",
      "+-------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrayArrayData = [\n",
    "  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n",
    "  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n",
    "  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86665d8-b35c-493e-8bac-bfe960a42609",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### exploding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a237c8f-3d40-4bb3-b0b5-fdd08f7bdc1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|name   |col               |\n",
      "+-------+------------------+\n",
      "|James  |[Java, Scala, C++]|\n",
      "|James  |[Spark, Java]     |\n",
      "|Michael|[Spark, Java, C++]|\n",
      "|Michael|[Spark, Java]     |\n",
      "|Robert |[CSharp, VB]      |\n",
      "|Robert |[Spark, Python]   |\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name, explode(df.subjects))\\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df8893-b543-495f-b048-919d48791c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d13156-1b19-4ade-86a8-557c504e5332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+\n",
      "|name   |subs                           |\n",
      "+-------+-------------------------------+\n",
      "|James  |[Java, Scala, C++, Spark, Java]|\n",
      "|Michael|[Spark, Java, C++, Spark, Java]|\n",
      "|Robert |[CSharp, VB, Spark, Python]    |\n",
      "+-------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import flatten\n",
    "df.select(df.name, flatten(df.subjects).alias(\"subs\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cad53f-642c-4e8c-a53d-71cbf9e8bfa9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085af0dc-9b51-45af-a912-1e74b4445167",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea2e3a0-e941-47d3-8a98-a41fdd9ec54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|name            |languagesAtSchool |languagesAtWork|currentState|previousState|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith    |[Java, Scala, C++]|[Spark, Java]  |OH          |CA           |\n",
      "|Michael,Rose,   |[Spark, Java, C++]|[Spark, Java]  |NY          |NJ           |\n",
      "|Robert,,Williams|[CSharp, VB]      |[Spark, Python]|UT          |NV           |\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True)\n",
    "  ])\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e6a541-359e-47f8-8b7d-271108737cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|            name|   col|\n",
      "+----------------+------+\n",
      "|    James,,Smith|  Java|\n",
      "|    James,,Smith| Scala|\n",
      "|    James,,Smith|   C++|\n",
      "|   Michael,Rose,| Spark|\n",
      "|   Michael,Rose,|  Java|\n",
      "|   Michael,Rose,|   C++|\n",
      "|Robert,,Williams|CSharp|\n",
      "|Robert,,Williams|    VB|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode example in array\n",
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name, explode(df.languagesAtSchool)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe13e1-81e9-43a1-9493-412171cbe4db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f712ae07-5bbf-4bf5-b731-3a02f5db924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|          split_name|languagesAtWork|\n",
      "+--------------------+---------------+\n",
      "|    [James, , Smith]|  [Spark, Java]|\n",
      "|   [Michael, Rose, ]|  [Spark, Java]|\n",
      "|[Robert, , Williams]|[Spark, Python]|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df.select(split(df.name, \",\").alias(\"split_name\"), df.languagesAtWork).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6e295-5d64-4379-a5ed-927e7433754a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ca51a3-52fc-463e-a606-3db7ac4c28e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|            name|   State|\n",
      "+----------------+--------+\n",
      "|    James,,Smith|[OH, CA]|\n",
      "|   Michael,Rose,|[NY, NJ]|\n",
      "|Robert,,Williams|[UT, NV]|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array\n",
    "df.select(df.name, array(df.currentState, df.previousState).alias('State'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dce919-062f-4ae5-af53-d501c427f8f6",
   "metadata": {},
   "source": [
    "### array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a99712e-8b1b-4bcb-9227-79a54e2e0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a lang to check if it exists :  Java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|            name|isExists|\n",
      "+----------------+--------+\n",
      "|    James,,Smith|    true|\n",
      "|   Michael,Rose,|    true|\n",
      "|Robert,,Williams|   false|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "row = input(\"Enter a lang to check if it exists : \")\n",
    "df.select(df.name, array_contains(df.languagesAtSchool,row).alias(\"isExists\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb5fed-7ec5-4683-9f21-01ef7e096c25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0f937-7965-4fa9-a612-3b0a3fe8532c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5590a674-7e6f-4605-96ad-3a14e914fd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|name            |languagesAtSchool |languagesAtWork|currentState|previousState|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith    |[Java, Scala, C++]|[Spark, Java]  |OH          |CA           |\n",
      "|Michael,Rose,   |[Spark, Java, C++]|[Spark, Java]  |NY          |NJ           |\n",
      "|Robert,,Williams|[CSharp, VB]      |[Spark, Python]|UT          |NV           |\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "\n",
      "+----------------+---------------+------------+-------------+---------+\n",
      "|name            |languagesAtWork|currentState|previousState|languages|\n",
      "+----------------+---------------+------------+-------------+---------+\n",
      "|James,,Smith    |[Spark, Java]  |OH          |CA           |Java     |\n",
      "|James,,Smith    |[Spark, Java]  |OH          |CA           |Scala    |\n",
      "|James,,Smith    |[Spark, Java]  |OH          |CA           |C++      |\n",
      "|Michael,Rose,   |[Spark, Java]  |NY          |NJ           |Spark    |\n",
      "|Michael,Rose,   |[Spark, Java]  |NY          |NJ           |Java     |\n",
      "|Michael,Rose,   |[Spark, Java]  |NY          |NJ           |C++      |\n",
      "|Robert,,Williams|[Spark, Python]|UT          |NV           |CSharp   |\n",
      "|Robert,,Williams|[Spark, Python]|UT          |NV           |VB       |\n",
      "+----------------+---------------+------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "df = df.withColumn(\"languages\", explode(\"languagesAtSchool\"))\\\n",
    "    .drop(\"languagesAtSchool\")\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab4cae1e-ab8f-4841-beca-74ad276aba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|collect_list(languages)                         |\n",
      "+------------------------------------------------+\n",
      "|[Java, Scala, C++, Spark, Java, C++, CSharp, VB]|\n",
      "+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_list(\"languages\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c01e7e-4dbe-4dbe-8938-cdddf6da873b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### collect_set() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bc206ab-a666-48c0-8842-bcfe4c82edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|collect_set(languages)               |\n",
      "+-------------------------------------+\n",
      "|[CSharp, VB, Scala, Spark, Java, C++]|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "df.select(collect_set(\"languages\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60193261-58e0-4f88-958f-0a147b048d7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### countDistinct() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d02359b8-bb95-421d-8ff0-ce832359a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(languages)|\n",
      "+----------------+\n",
      "|               8|\n",
      "+----------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT languages)|\n",
      "+-------------------------+\n",
      "|                        6|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, count\n",
    "df.select(count(\"languages\")).show()\n",
    "df.select(countDistinct(\"languages\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f22e9-0b0f-48ff-95aa-94c2d454c843",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Map functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a6911-cbcb-484b-9a9e-07e9a6ca098b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### create_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7788f89-a648-4541-9048-b66264285068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n",
      "+-----+---------+------+--------+\n",
      "|id   |dept     |salary|location|\n",
      "+-----+---------+------+--------+\n",
      "|36636|Finance  |3000  |USA     |\n",
      "|40288|Finance  |5000  |IND     |\n",
      "|42114|Sales    |3900  |USA     |\n",
      "|39192|Marketing|2500  |CAN     |\n",
      "|34534|Sales    |6500  |USA     |\n",
      "+-----+---------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType\n",
    "data = [ (\"36636\",\"Finance\",3000,\"USA\"), \n",
    "    (\"40288\",\"Finance\",5000,\"IND\"), \n",
    "    (\"42114\",\"Sales\",3900,\"USA\"), \n",
    "    (\"39192\",\"Marketing\",2500,\"CAN\"), \n",
    "    (\"34534\",\"Sales\",6500,\"USA\") ]\n",
    "schema = StructType([\n",
    "     StructField('id', StringType(), True),\n",
    "     StructField('dept', StringType(), True),\n",
    "     StructField('salary', IntegerType(), True),\n",
    "     StructField('location', StringType(), True)\n",
    "     ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58d4b2b2-0f7c-4473-b55c-e8848419a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------------------------+\n",
      "|id   |dept     |properitiesMap                   |\n",
      "+-----+---------+---------------------------------+\n",
      "|36636|Finance  |{salary -> 3000, location -> USA}|\n",
      "|40288|Finance  |{salary -> 5000, location -> IND}|\n",
      "|42114|Sales    |{salary -> 3900, location -> USA}|\n",
      "|39192|Marketing|{salary -> 2500, location -> CAN}|\n",
      "|34534|Sales    |{salary -> 6500, location -> USA}|\n",
      "+-----+---------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe columns to Map Type\n",
    "from pyspark.sql.functions import create_map, lit, col\n",
    "df.withColumn(\"properitiesMap\", create_map(\n",
    "    lit(\"salary\"), col(\"salary\"),\n",
    "    lit(\"location\"), col(\"location\")\n",
    "))\\\n",
    "    .drop(\"salary\", \"location\")\\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de6ce-6abb-4e9f-936e-713a27e9eabc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Exploding Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a0bd6ce-16ed-4d9a-9d26-c5e0d60a926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import MapType\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties', MapType(StringType(),StringType()),True)\n",
    "])\n",
    "dataDictionary = [\n",
    "        ('James',{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',{'hair':'brown','eye':None}),\n",
    "        ('Robert',{'hair':'red','eye':'black'}),\n",
    "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
    "        ('Jefferson',{'hair':'brown','eye':''})\n",
    "        ]\n",
    "df = spark.createDataFrame(data=dataDictionary, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3b23055-0332-4719-b928-c7852bffe116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.rdd.map(lambda x : \\\n",
    "                (x.name, x.properties[\"hair\"], x.properties[\"eye\"]))\\\n",
    "    .toDF([\"name\", \"hair\", \"eye\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c958d8f-dbdd-4d81-91a8-e6a82f413caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|black|\n",
      "|    Robert|hair|  red|\n",
      "|Washington| eye| grey|\n",
      "|Washington|hair| grey|\n",
      "| Jefferson| eye|     |\n",
      "| Jefferson|hair|brown|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, explode(df.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db618350-7af0-4577-91a4-e745980ac201",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### map_key() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9011dedc-a061-4aa1-ac27-b770f37c02a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|map_keys(properties)|\n",
      "+----------+--------------------+\n",
      "|     James|         [eye, hair]|\n",
      "|   Michael|         [eye, hair]|\n",
      "|    Robert|         [eye, hair]|\n",
      "|Washington|         [eye, hair]|\n",
      "| Jefferson|         [eye, hair]|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "df.select(df.name, map_keys(df.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc91bcf-983c-4fbb-ba37-308a23c05881",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### map_values() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36c6cbc8-809e-46f4-9fa2-76b62d439541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+\n",
      "|      name|map_values(properties)|\n",
      "+----------+----------------------+\n",
      "|     James|        [brown, black]|\n",
      "|   Michael|         [null, brown]|\n",
      "|    Robert|          [black, red]|\n",
      "|Washington|          [grey, grey]|\n",
      "| Jefferson|             [, brown]|\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_values\n",
    "df.select(df.name, map_values(df.properties)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
