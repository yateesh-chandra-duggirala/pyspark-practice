{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a9cc48-782d-4be6-ad70-f5175be5a7a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4678e6a6-4dd2-496d-b01e-4a908f541fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ba0c8-38e7-42bb-a865-346482c43302",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f8789b-f2ce-4736-b123-3f7dd5fa1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"JSON Functions\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b819b3bd-67de-41df-a90b-8dac066f946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = \"\"\"{\"ZipCode\" : 704, \"ZipCodeType\" : \"Standard\", \"City\" : \"PARC PARQUE\", \"Country\" : \"PR\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8951dd4-d093-448e-a7f9-14d094afd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------------------+\n",
      "|id |value                                                                                  |\n",
      "+---+---------------------------------------------------------------------------------------+\n",
      "|1  |{\"ZipCode\" : 704, \"ZipCodeType\" : \"Standard\", \"City\" : \"PARC PARQUE\", \"Country\" : \"PR\"}|\n",
      "+---+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(1, json_string)], [\"id\", \"value\"])\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09996853-8330-411b-b0bb-a9824d9207f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Json Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2402a57-89fe-48f3-a9fc-d2fd6783842c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704fb7c-c204-43dc-88ef-a7f88e7ea7f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43785e90-1682-440c-9722-1e116658faa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------+\n",
      "|id |value                                                                        |\n",
      "+---+-----------------------------------------------------------------------------+\n",
      "|1  |{ZipCode -> 704, ZipCodeType -> Standard, City -> PARC PARQUE, Country -> PR}|\n",
      "+---+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import MapType, StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "df2 = df.withColumn(\"value\", from_json(df.value, MapType(StringType(), StringType())))\n",
    "df2.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3139b10-13cf-4a7a-b38a-56d80ba0272e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110a181e-4e0d-4c72-9308-759082616a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- ZipCode: string (nullable = true)\n",
      " |    |-- ZipCodeType: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- Country: string (nullable = true)\n",
      "\n",
      "+---+--------------------------------+\n",
      "|id |value                           |\n",
      "+---+--------------------------------+\n",
      "|1  |{704, Standard, PARC PARQUE, PR}|\n",
      "+---+--------------------------------+\n",
      "\n",
      "+---+-------+-----------+-----------+-------+\n",
      "|id |ZipCode|ZipCodeType|City       |Country|\n",
      "+---+-------+-----------+-----------+-------+\n",
      "|1  |704    |Standard   |PARC PARQUE|PR     |\n",
      "+---+-------+-----------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Creating Schema for JSON\n",
    "schema = StructType([\n",
    "    StructField(\"ZipCode\", StringType(), True),\n",
    "    StructField(\"ZipCodeType\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Converting JSON String to Struct Type\n",
    "df3 = df.withColumn(\"value\", from_json(df.value, schema))\n",
    "df3.printSchema()\n",
    "df3.show(truncate = False)\n",
    "\n",
    "# converting to multiple columns\n",
    "df4 = df3.select(\"id\", \"value.*\")\n",
    "df4.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93710dc-10cc-47de-af00-1dca094ae4f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0bc5ff-62e7-4f4d-bcd8-e6bdfb4912ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------+\n",
      "|id |value                                                                         |\n",
      "+---+------------------------------------------------------------------------------+\n",
      "|1  |{\"ZipCode\":\"704\",\"ZipCodeType\":\"Standard\",\"City\":\"PARC PARQUE\",\"Country\":\"PR\"}|\n",
      "+---+------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json, col\n",
    "df2.withColumn(\"value\", to_json(col(\"value\"))) \\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231e758-a783-4541-a595-4c89c99e22d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. json_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65274716-aee8-4943-9828-9a008b58315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+\n",
      "|Id |Zip|ZipType |\n",
      "+---+---+--------+\n",
      "|1  |704|Standard|\n",
      "+---+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import json_tuple\n",
    "df.select(col(\"id\"), json_tuple(col(\"value\"), \"ZipCode\", \"ZipCodeType\"))\\\n",
    "    .toDF(\"Id\", \"Zip\", \"ZipType\")\\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a679341-24b0-4bef-a883-0de29bc3cbd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. get_json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ac6899d-9915-4832-aa49-3393dc33ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+\n",
      "|id |Code|Country|\n",
      "+---+----+-------+\n",
      "|1  |704 |PR     |\n",
      "+---+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "df.select(col(\"id\"), get_json_object(col(\"value\"), \"$.ZipCode\").alias(\"Code\"), get_json_object(col(\"value\"), \"$.Country\").alias(\"Country\")) \\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83e3f9-c52e-464b-a9d0-455f27a77784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. schema_of_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aac5c4b-1981-4427-88d1-1566860d3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRUCT<City: STRING, Country: STRING, ZipCode: BIGINT, ZipCodeType: STRING>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import schema_of_json, lit\n",
    "schemaStr = spark.range(1) \\\n",
    "    .select(schema_of_json(lit(json_string))) \\\n",
    "    .collect()[0][0]\n",
    "print(schemaStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
