{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d411de8",
   "metadata": {},
   "source": [
    "# Pyspark Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec4b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b524566",
   "metadata": {},
   "source": [
    "# Get started With First Spark Session Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788167dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Sparksession\") \\\n",
    "        .master(\"local\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1041f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://yateed3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sparksession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e125282150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75929757",
   "metadata": {},
   "source": [
    "# Creating Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266b817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "# Creating an Empty RDD\n",
    "rdd = spark.sparkContext.emptyRDD()\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85d520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define the schema according to our wish.\n",
    "schema = StructType([\n",
    "    StructField('First name', StringType(), True),\n",
    "    StructField('Middle name', StringType(), True),\n",
    "    StructField('Last name', StringType(), True)\n",
    "    ])\n",
    "\n",
    "# load into Dataframe from the Empty RDD\n",
    "df = spark.createDataFrame(rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fd8ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- First name: string (nullable = true)\n",
      " |-- Middle name: string (nullable = true)\n",
      " |-- Last name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To check the Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342f07c",
   "metadata": {},
   "source": [
    "### Converting an existing RDD to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92036099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[First name: string, Middle name: string, Last name: string]\n"
     ]
    }
   ],
   "source": [
    "df1 = rdd.toDF(schema)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186317e2",
   "metadata": {},
   "source": [
    "### Creating an empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b608583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[First name: string, Middle name: string, Last name: string]\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame([],schema)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eff8f",
   "metadata": {},
   "source": [
    "### Creating Empty DataFrame without any schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd24ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame([], StructType([]))\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe81175",
   "metadata": {},
   "source": [
    "# Converting Pyspark RDD to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd0e2e",
   "metadata": {},
   "source": [
    "### 1. Convert Pyspark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc3d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PySpark RDD\n",
    "dept = [(\"Finance\", 300), (\"Marketing\", 450), (\"Promotions\", 250)]\n",
    "rdd = spark.sparkContext.parallelize(dept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6c558",
   "metadata": {},
   "source": [
    "### 2. Convert Pyspark RDD to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97198d02",
   "metadata": {},
   "source": [
    "#### a. Using toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c82214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without columns\n",
    "df = rdd.toDF()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7835541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      "\n",
      "+----------+---+\n",
      "|Sector    |Id |\n",
      "+----------+---+\n",
      "|Finance   |300|\n",
      "|Marketing |450|\n",
      "|Promotions|250|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With Desired Column Names\n",
    "columns = [\"Sector\", \"Id\"]\n",
    "df = rdd.toDF(columns)\n",
    "df.printSchema()\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc1d53",
   "metadata": {},
   "source": [
    "#### b. createDataFrame() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f633ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|    Sector| Id|\n",
      "+----------+---+\n",
      "|   Finance|300|\n",
      "| Marketing|450|\n",
      "|Promotions|250|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(rdd, schema = columns)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f840b",
   "metadata": {},
   "source": [
    "# Creating a Data Frame into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6f566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Sector   Id\n",
      "0     Finance  300\n",
      "1   Marketing  450\n",
      "2  Promotions  250\n"
     ]
    }
   ],
   "source": [
    "df_pandas = df.toPandas()\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c58020",
   "metadata": {},
   "source": [
    "# Show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1312b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Seqno\",\"Quote\"]\n",
    "data = [(\"1\", \"Be the change that you wish to see in the world\"),\n",
    "    (\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n",
    "    (\"3\", \"The purpose of our lives is to be happy.\"),\n",
    "    (\"4\", \"Be cool.\")]\n",
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac41537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Seqno|               Quote|\n",
      "+-----+--------------------+\n",
      "|    1|Be the change tha...|\n",
      "|    2|Everyone thinks o...|\n",
      "|    3|The purpose of ou...|\n",
      "|    4|            Be cool.|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the contents upto 20 characters in the values of the columns\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d1ef26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Seqno|               Quote|\n",
      "+-----+--------------------+\n",
      "|    1|Be the change tha...|\n",
      "|    2|Everyone thinks o...|\n",
      "|    3|The purpose of ou...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you pass the value as a parameter to the show(), That number of rows will be displayed\n",
    "df.show(3)   # here n = 3, stands for the number of rows to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86f1faa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------+\n",
      "|Seqno|                                   Quote|\n",
      "+-----+----------------------------------------+\n",
      "|    1|Be the change that you wish to see in...|\n",
      "|    2|Everyone thinks of changing the world...|\n",
      "|    3|The purpose of our lives is to be happy.|\n",
      "|    4|                                Be cool.|\n",
      "+-----+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When the truncate value is set to any value(viz, 40). Only 40 characters is displayed from the characters of the column value\n",
    "df.show(truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7df7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "|3    |The purpose of our lives is to be happy.                                     |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When the truncate value is set to False, The Characters in the columns will be completely displayed\n",
    "df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f64368e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------\n",
      " Seqno | 1                                                                             \n",
      " Quote | Be the change that you wish to see in the world                               \n",
      "-RECORD 1------------------------------------------------------------------------------\n",
      " Seqno | 2                                                                             \n",
      " Quote | Everyone thinks of changing the world, but no one thinks of changing himself. \n",
      "-RECORD 2------------------------------------------------------------------------------\n",
      " Seqno | 3                                                                             \n",
      " Quote | The purpose of our lives is to be happy.                                      \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you want to display the details vertically, we use the vertical = true\n",
    "df.show(n = 3, truncate = False, vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e156c2",
   "metadata": {},
   "source": [
    "# StructType and StructField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a48fa0",
   "metadata": {},
   "source": [
    "## Define columns with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71dfc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from pyspark.sql.types import StructType, StringType, StructField, IntegerType, FloatType\n",
    "\n",
    "# Create schema\n",
    "schema = StructType([\n",
    "    StructField('Student Id', IntegerType(), True),\n",
    "    StructField('First Name', StringType(), True),\n",
    "    StructField('Last Name', StringType(), True),\n",
    "    StructField('Attendance', FloatType(), True)\n",
    "])\n",
    "\n",
    "# Create Data to insert\n",
    "data = [\n",
    "    (1, \"Santhosh\", \"Sharma\", 89.07),\n",
    "    (2, \"Mahesh\", \"\", 73.89),\n",
    "    (3, \"Yateesh\", \"Chandra\", 92.676),\n",
    "    (4, \"Kranthi\", \"Chanpathi\", 87.273),\n",
    "    (5, \"Samdhani\", \"\", 84.30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10b8465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Student Id: integer (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Attendance: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Viewing the Schema of the Data frame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95b36ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+----------+\n",
      "|Student Id|First Name|Last Name|Attendance|\n",
      "+----------+----------+---------+----------+\n",
      "|         1|  Santhosh|   Sharma|     89.07|\n",
      "|         2|    Mahesh|         |     73.89|\n",
      "|         3|   Yateesh|  Chandra|    92.676|\n",
      "|         4|   Kranthi|Chanpathi|    87.273|\n",
      "|         5|  Samdhani|         |      84.3|\n",
      "+----------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the data from the database\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185c3b9",
   "metadata": {},
   "source": [
    "## Nesting the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557b6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesting the data\n",
    "structure_data = [\n",
    "    (1, (\"Dhilli\", \"\"), 23.40),\n",
    "    (2, (\"Rolex\", \"Watson\"), 85.34),\n",
    "    (3, (\"Amar\",\"\"), 12.43),\n",
    "    (4, (\"Leo\", \"Das\"), 98.23),\n",
    "    (5, (\"Vikram\", \"Iyer\"), 2.09)\n",
    "]\n",
    "\n",
    "# Nested Schema Structure\n",
    "structured_schema = StructType([\n",
    "    StructField(\"Criminal Id\", IntegerType(), True),\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"first Name\", StringType(), True),\n",
    "        StructField(\"last Name\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"Criminal Percent\", FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c82920f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcu_df = spark.createDataFrame(structure_data, structured_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e47e9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Criminal Id: integer (nullable = true)\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first Name: string (nullable = true)\n",
      " |    |-- last Name: string (nullable = true)\n",
      " |-- Criminal Percent: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lcu_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6fa3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------------+\n",
      "|Criminal Id|name           |Criminal Percent|\n",
      "+-----------+---------------+----------------+\n",
      "|1          |{Dhilli, }     |23.4            |\n",
      "|2          |{Rolex, Watson}|85.34           |\n",
      "|3          |{Amar, }       |12.43           |\n",
      "|4          |{Leo, Das}     |98.23           |\n",
      "|5          |{Vikram, Iyer} |2.09            |\n",
      "+-----------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lcu_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a021b",
   "metadata": {},
   "source": [
    "## Updating the structure of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bffc34d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Student Id: integer (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Attendance: float (nullable = true)\n",
      " |-- Other Info: struct (nullable = false)\n",
      " |    |-- id: integer (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |    |-- percent: float (nullable = true)\n",
      " |    |-- Eligibility: string (nullable = false)\n",
      "\n",
      "+----------+----------+---------+----------+-----------------------------------------+\n",
      "|Student Id|First Name|Last Name|Attendance|Other Info                               |\n",
      "+----------+----------+---------+----------+-----------------------------------------+\n",
      "|1         |Santhosh  |Sharma   |89.07     |{1, Santhosh, Sharma, 89.07, Eligible}   |\n",
      "|2         |Mahesh    |         |73.89     |{2, Mahesh, , 73.89, Not Eligible}       |\n",
      "|3         |Yateesh   |Chandra  |92.676    |{3, Yateesh, Chandra, 92.676, Eligible}  |\n",
      "|4         |Kranthi   |Chanpathi|87.273    |{4, Kranthi, Chanpathi, 87.273, Eligible}|\n",
      "|5         |Samdhani  |         |84.3      |{5, Samdhani, , 84.3, Eligible}          |\n",
      "+----------+----------+---------+----------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, struct\n",
    "\n",
    "# Updating the schema\n",
    "updated_df = df.withColumn(\"Other Info\",\n",
    "        struct(col(\"Student Id\").alias(\"id\"),\n",
    "               col(\"First Name\").alias(\"first_name\"),\n",
    "               col(\"last Name\").alias(\"last_name\"),\n",
    "               col(\"Attendance\").alias(\"percent\"),\n",
    "               when(col(\"Attendance\").cast(IntegerType()) < 75, \"Not Eligible\")\n",
    "               .otherwise(\"Eligible\").alias(\"Eligibility\")\n",
    "        ))\n",
    "#     ).drop(\"Student Id\", \"First Name\", \"Last Name\", \"Attendance\")\n",
    "\n",
    "updated_df.printSchema()\n",
    "updated_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527110b",
   "metadata": {},
   "source": [
    "## Adding the new columns to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1924ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_with_eligibility = df.withColumn(\"Eligibility\",\n",
    "                                           when(col(\"Attendance\").cast(IntegerType()) < 75, \"No\")\n",
    "                                           .otherwise(\"Yes\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cd447fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Student Id: integer (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Attendance: float (nullable = true)\n",
      " |-- Eligibility: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_df_with_eligibility.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d26cb27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+----------+-----------+\n",
      "|Student Id|First Name|Last Name|Attendance|Eligibility|\n",
      "+----------+----------+---------+----------+-----------+\n",
      "|1         |Santhosh  |Sharma   |89.07     |Yes        |\n",
      "|2         |Mahesh    |         |73.89     |No         |\n",
      "|3         |Yateesh   |Chandra  |92.676    |Yes        |\n",
      "|4         |Kranthi   |Chanpathi|87.273    |Yes        |\n",
      "|5         |Samdhani  |         |84.3      |Yes        |\n",
      "+----------+----------+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_df_with_eligibility.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb34035a",
   "metadata": {},
   "source": [
    "## Using SQL Array and Map Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d37a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the arrayType and MapType from the pyspark.sql.types\n",
    "from pyspark.sql.types import ArrayType, MapType\n",
    "\n",
    "arrayAndMapSchema = StructType([\n",
    "    StructField(\"First Name\",StringType(), True),\n",
    "    StructField(\"Last Name\", StringType(), True),\n",
    "    StructField(\"Attendance\", FloatType(), True),\n",
    "    StructField(\"Hobbies\", ArrayType(StringType()), True),\n",
    "    StructField(\"Properties\", MapType(StringType(), StringType()), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9bc95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fields\":[{\"metadata\":{},\"name\":\"Student Id\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"First Name\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"Last Name\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"Attendance\",\"nullable\":true,\"type\":\"float\"}],\"type\":\"struct\"}\n"
     ]
    }
   ],
   "source": [
    "# If there are more number of columns,we can use the schema.json() method to print the Schema in json format.\n",
    "print(df.schema.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e24673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct<Student Id:int,First Name:string,Last Name:string,Attendance:float>\n"
     ]
    }
   ],
   "source": [
    "# To print it in the simplest format, we can use the simpleString() method\n",
    "print(df.schema.simpleString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3b1ff",
   "metadata": {},
   "source": [
    "# Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c18499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"First Name\", \"first_name\")\\\n",
    "    .withColumnRenamed(\"Last Name\", \"last_name\")\\\n",
    "        .withColumnRenamed(\"Student Id\", \"student_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf5a6f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "data_df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f1d5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "data_df.toDF(*newColumns).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23d1dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'dob', 'gender', 'salary']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b186d9",
   "metadata": {},
   "source": [
    "# Column Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "955f2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "colObj  = lit(\"sparkbyexamples.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "672c7a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Criminal Id: integer (nullable = true)\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first Name: string (nullable = true)\n",
      " |    |-- last Name: string (nullable = true)\n",
      " |-- Criminal Percent: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lcu_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36045aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Attendance|\n",
      "+----------+\n",
      "|     89.07|\n",
      "|     73.89|\n",
      "|    92.676|\n",
      "|    87.273|\n",
      "|      84.3|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using . operator\n",
    "df.select(df.Attendance).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ab8180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|  Santhosh|   Sharma|\n",
      "|    Mahesh|         |\n",
      "|   Yateesh|  Chandra|\n",
      "|   Kranthi|Chanpathi|\n",
      "|  Samdhani|         |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using df[\"Column Name\"]\n",
    "df.select(df[\"first_name\"], df[\"last_name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ea2b9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|student_id|first_name|\n",
      "+----------+----------+\n",
      "|         1|  Santhosh|\n",
      "|         2|    Mahesh|\n",
      "|         3|   Yateesh|\n",
      "|         4|   Kranthi|\n",
      "|         5|  Samdhani|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using col function\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"student_id\"),col(\"first_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e95e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|first name|\n",
      "+----------+\n",
      "|    Dhilli|\n",
      "|     Rolex|\n",
      "|      Amar|\n",
      "|       Leo|\n",
      "|    Vikram|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lcu_df.select(lcu_df[\"name.first name\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7791e9",
   "metadata": {},
   "source": [
    "## Creating a DataFrame using Row Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab3888b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "data = [Row(name = \"James\", prop = Row(hair = \"black\", eye = \"brown\")),\n",
    "       Row(name = \"Rahul\", prop = Row(hair = \"blue\", eye = \"reddish\"))]\n",
    "\n",
    "df_prop = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6364f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| hair|  eye|\n",
      "+-----+-----+\n",
      "|black|brown|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prop.select(col(\"prop.*\")).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ba25c",
   "metadata": {},
   "source": [
    "## Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60bbd565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(150, 23, 8), (180, 43, 5), (129, 85, 1)]\n",
    "ndf = spark.createDataFrame(data).toDF(\"col1\", \"col2\", \"col3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "210d3a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "| 150|  23|   8|\n",
      "+----+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3081b4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Sum|\n",
      "+---+\n",
      "|173|\n",
      "|223|\n",
      "|214|\n",
      "+---+\n",
      "\n",
      "+-------------+\n",
      "|(col1 - col2)|\n",
      "+-------------+\n",
      "|          127|\n",
      "|          137|\n",
      "|           44|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 * col3)|\n",
      "+-------------+\n",
      "|         1200|\n",
      "|          900|\n",
      "|          129|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 / col3)|\n",
      "+-------------+\n",
      "|        18.75|\n",
      "|         36.0|\n",
      "|        129.0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 % col3)|\n",
      "+-------------+\n",
      "|            6|\n",
      "|            0|\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "+-------------+\n",
      "|(col1 < col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 > col3)|\n",
      "+-------------+\n",
      "|         true|\n",
      "|         true|\n",
      "|         true|\n",
      "+-------------+\n",
      "\n",
      "+--------------+\n",
      "|(col1 <= col3)|\n",
      "+--------------+\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "+--------------+\n",
      "\n",
      "+--------------+\n",
      "|(col1 >= col3)|\n",
      "+--------------+\n",
      "|          true|\n",
      "|          true|\n",
      "|          true|\n",
      "+--------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 = col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndf.select((ndf[\"col1\"] + ndf[\"col2\"]).alias(\"Sum\")).show()\n",
    "ndf.select(ndf[\"col1\"] - ndf[\"col2\"]).show()\n",
    "ndf.select(ndf[\"col1\"] * ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] / ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] % ndf[\"col3\"]).show()\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "ndf.select(ndf[\"col1\"] < ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] > ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] <= ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] >= ndf[\"col3\"]).show()\n",
    "ndf.select(ndf[\"col1\"] == ndf[\"col3\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20412e46",
   "metadata": {},
   "source": [
    "## PySpark Column Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a24670f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|substring(last_name, 1, 2)|\n",
      "+--------------------------+\n",
      "|                        Sh|\n",
      "|                          |\n",
      "|                        Ch|\n",
      "|                        Ch|\n",
      "|                          |\n",
      "+--------------------------+\n",
      "\n",
      "+------------------------+\n",
      "|startswith(last_name, C)|\n",
      "+------------------------+\n",
      "|                   false|\n",
      "|                   false|\n",
      "|                    true|\n",
      "|                    true|\n",
      "|                   false|\n",
      "+------------------------+\n",
      "\n",
      "+----------------------+\n",
      "|endswith(last_name, a)|\n",
      "+----------------------+\n",
      "|                  true|\n",
      "|                 false|\n",
      "|                  true|\n",
      "|                 false|\n",
      "|                 false|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# substr (starting Position, length of the substring you wish to return) \n",
    "df.select(col(\"last_name\").substr(1,2)).show()\n",
    "\n",
    "# starts with checks whether the item starts with a specific character or not\n",
    "df.select(col(\"last_name\").startswith('C')).show()\n",
    "\n",
    "# ends with checks whether the item starts ends with a specific character or not\n",
    "df.select(col(\"last_name\").endswith('a')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
