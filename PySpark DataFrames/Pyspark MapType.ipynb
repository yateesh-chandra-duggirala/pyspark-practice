{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4dff8d6-66e5-49ea-ac73-46d0507e9fd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fd5a7d-14d8-429d-be0a-ba43b583134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b0d92-e8d9-4fae-9311-b28039aa135d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0861f7c-b6c1-410b-ad02-a209b30e21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"MapType\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce281c8a-feb3-4620-8f07-2049814f8b5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b33e6bf-8c42-42f4-85b7-3f09b842011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, MapType\n",
    "\n",
    "# Define Schema\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties',MapType(StringType(), StringType()), True)\n",
    "])\n",
    "\n",
    "# Define Data\n",
    "dataDictionary = [\n",
    "        ('James',{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',{'hair':'brown','eye':None}),\n",
    "        ('Robert',{'hair':'red','eye':'black'}),\n",
    "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
    "        ('Jefferson',{'hair':'brown','eye':''})\n",
    "        ]\n",
    "df = spark.createDataFrame(data=dataDictionary, schema = schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6095420-bc69-4b45-a5ce-01850380512c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------+\n",
      "|name      |properties                   |\n",
      "+----------+-----------------------------+\n",
      "|James     |{eye -> brown, hair -> black}|\n",
      "|Michael   |{eye -> null, hair -> brown} |\n",
      "|Robert    |{eye -> black, hair -> red}  |\n",
      "|Washington|{eye -> grey, hair -> grey}  |\n",
      "|Jefferson |{eye -> , hair -> brown}     |\n",
      "+----------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16641c2c-3d75-4998-be57-5575ed3e23c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Accessing Elements of MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523460c3-a3f2-4365-91a4-e10937003f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df.rdd.map(lambda x: \\\n",
    "                (x.name, x.properties[\"hair\"], x.properties[\"eye\"])) \\\n",
    "                .toDF([\"name\", \"hair\", \"eye\"])\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b4c5a6-73f7-4132-87c5-3a3dc0a777ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"hair\", df.properties.getItem(\"hair\"))\\\n",
    "    .withColumn(\"eye\", df.properties.getItem(\"eye\"))\\\n",
    "    .drop(\"properties\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9372a302-a4df-4db3-b56b-e015d72757fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"hair\", df.properties[\"hair\"])\\\n",
    "    .withColumn(\"eye\", df.properties[\"eye\"])\\\n",
    "    .drop(\"properties\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe5394-8b36-4e28-a6c1-b55e85265551",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions used for MapType()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea8cd5-a90d-43bc-8776-2d0d5b443154",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4b1102-f3e9-4d40-970a-2fd07c3f786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|black|\n",
      "|    Robert|hair|  red|\n",
      "|Washington| eye| grey|\n",
      "|Washington|hair| grey|\n",
      "| Jefferson| eye|     |\n",
      "| Jefferson|hair|brown|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name, explode(df.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390e012-03d5-44a2-80ee-cce3b8992639",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Map_Keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00467cc7-2078-4cd2-af66-af17725331e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|map_keys(properties)|\n",
      "+----------+--------------------+\n",
      "|     James|         [eye, hair]|\n",
      "|   Michael|         [eye, hair]|\n",
      "|    Robert|         [eye, hair]|\n",
      "|Washington|         [eye, hair]|\n",
      "| Jefferson|         [eye, hair]|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "df.select(df.name, map_keys(df.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d14ba-8a08-43af-83e1-5c2fc979434f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Map_Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44da5e59-47e8-4e5a-b6ed-94d9fd7ea57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+\n",
      "|      name|map_values(properties)|\n",
      "+----------+----------------------+\n",
      "|     James|        [brown, black]|\n",
      "|   Michael|         [null, brown]|\n",
      "|    Robert|          [black, red]|\n",
      "|Washington|          [grey, grey]|\n",
      "| Jefferson|             [, brown]|\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_values\n",
    "df.select(df.name, map_values(df.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef025b59-c9d1-4fb4-a2bb-a0cdd22168bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Map Keys List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccc19837-901a-43b5-acc6-fd61b8a28de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye', 'hair']\n"
     ]
    }
   ],
   "source": [
    "keysDf = df.select(explode(map_keys(df.properties))).distinct()\n",
    "keysList = keysDf.rdd.map(lambda x : x[0]).collect()\n",
    "print(keysList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cf9ea-e375-4a55-bec0-d2884d893b9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Map Values List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05302e1b-d2d2-4b04-9b27-a7563950567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'brown', None, 'red', 'grey', '']\n"
     ]
    }
   ],
   "source": [
    "keysDf = df.select(explode(map_values(df.properties))).distinct()\n",
    "keysList = keysDf.rdd.map(lambda x : x[0]).collect()\n",
    "print(keysList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
