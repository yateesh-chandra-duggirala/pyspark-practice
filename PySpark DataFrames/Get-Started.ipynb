{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d411de8",
   "metadata": {},
   "source": [
    "# Pyspark Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec4b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b524566",
   "metadata": {},
   "source": [
    "# Get started With First Spark Session Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788167dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Sparksession\") \\\n",
    "        .master(\"local\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7411a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "| Alice| 23|\n",
      "|   Bob| 30|\n",
      "|Mahesh| 21|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the data\n",
    "data = [(\"Alice\", 23),(\"Bob\", 30),(\"Mahesh\", 21)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "#Let us show the data using show() method\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d9860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7dec0",
   "metadata": {},
   "source": [
    "# Difference Between SparkContext and SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada99ee",
   "metadata": {},
   "source": [
    "Spark Context :\n",
    "- Used to be the entry point for spark in the earlier versions say 1.x\n",
    "- Represents connection to spark cluster\n",
    "- Coordinates task execution across the cluster\n",
    "- Creates RDDs (Resilient Distributed Datasets)\n",
    "- Performs Transformations and defines actions.\n",
    "\n",
    "Spark Session :\n",
    "- The entry point for Spark since the version 2.0 that provides simple Interaction.\n",
    "- Combines the Functionalities like HiveContext, SparkContext, SQLContext and StreamingContext.\n",
    "- Supports multiple Programming Languages like : Scala, Java, R and Python\n",
    "- Extends the functionality of Spark Context.\n",
    "- Supports Advanced abstractions like Datasets and DataFrames\n",
    "- Provides Data Source APIs, Machine Learning Algorithms and streaming capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d09702",
   "metadata": {},
   "source": [
    "## Creating PySpark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8bbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Create a Spark Context Variable\n",
    "sc = SparkContext(appName=\"MySparkContext-Application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee3adc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://yateed3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MySparkContext-Application</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=MySparkContext-Application>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8bb322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the Spark Context\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69027b1",
   "metadata": {},
   "source": [
    "# Creating Spark Session with Manual Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2347fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Spark-Session-Manual-Config\") \\\n",
    "        .config(\"spark.executor.memory\", \"2g\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57873e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://yateed3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark-Session-Manual-Config</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c96e379250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6062d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262d53",
   "metadata": {},
   "source": [
    "# RDDs (Resilient Distributed Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60273a29",
   "metadata": {},
   "source": [
    "- Backbone of data processing in Spark\n",
    "- Distributed, Fault-tolerant, parallelizable data structure\n",
    "- Efficiently processes large datasets across the cluster\n",
    "- RDDs are immutable, distributed, resilient, lazily evaluated, fault-tolerant\n",
    "- Fault Tolerant operations may contain : map, filter, reduce, collect, count, save, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa563fc",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "- Create new RDDs by applying computation/ Manipulation\n",
    "- Lazy Evaluation, Lineage Graph\n",
    "- Examples like map, filter, flatMap, reduceByKey, sortBy and join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3852fb4",
   "metadata": {},
   "source": [
    "## Actions\n",
    "\n",
    "- Return Results or perform actions on RDD, triggering execution\n",
    "- Eager evaluation, data movement/ computation\n",
    "- Examples like collect, count, first, take, save, foreach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d566426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD-SparkSession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e47ec9",
   "metadata": {},
   "source": [
    "## How to Create RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c689cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7d2117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect method retrieves all elements from the RDD\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ce1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD from the List of Tuples\n",
    "employees = [(\"Ajay\", 8), (\"Raman\", 7), (\"Pratap\", 5), (\"Mohan\", 6), (\"Raman\", 3)]\n",
    "employees_rdd = spark.sparkContext.parallelize(employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826f1e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the employee tuples :\n",
      "('Ajay', 8)\n",
      "('Raman', 7)\n",
      "('Pratap', 5)\n",
      "('Mohan', 6)\n",
      "('Raman', 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"All the employee tuples :\")\n",
    "\n",
    "## How to Create RDDs# Print the tuples in new line\n",
    "for i in employees_rdd.collect():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b668b8f",
   "metadata": {},
   "source": [
    "## RDDs - Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470fb3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of items in the RDD : 5\n"
     ]
    }
   ],
   "source": [
    "# Count() action is used to count the items in the RDD.\n",
    "\n",
    "# Create a count variable to store the number of items in the rdd\n",
    "rdd_count = rdd.count()\n",
    "print(\"The total number of items in the RDD :\",rdd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f102697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of items in the Employee RDD is :  5\n"
     ]
    }
   ],
   "source": [
    "employee_rdd_count = employees_rdd.count()\n",
    "print(\"The total number of items in the Employee RDD is : \", employee_rdd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aad221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first item in the RDD is :  ('Ajay', 8)\n"
     ]
    }
   ],
   "source": [
    "# first() action returns the first action from the RDD.\n",
    "first_item = employees_rdd.first()\n",
    "print(\"The first item in the RDD is : \", first_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91370fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elements from the RDD are : \n",
      "('Ajay', 8)\n",
      "('Raman', 7)\n",
      "('Pratap', 5)\n"
     ]
    }
   ],
   "source": [
    "# take() action is used to retrieve the n number of elements from the RDD\n",
    "elements_needed = employees_rdd.take(3)\n",
    "print(\"The elements from the RDD are : \")\n",
    "for i in elements_needed :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9d4c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foreach() action is used to print each element of the rdd\n",
    "employees_rdd.foreach(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746a849",
   "metadata": {},
   "source": [
    "## RDDs - Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef78d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Transformations, the data will be changed but only returns result when any action is performed\n",
    "\n",
    "# Map Transformations are done to convert the name to uppercase\n",
    "mapped_rdd = employees_rdd.map(lambda x: (x[0].upper(), x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89afab17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD in Upper case : [('AJAY', 8), ('RAMAN', 7), ('PRATAP', 5), ('MOHAN', 6), ('RAMAN', 3)]\n"
     ]
    }
   ],
   "source": [
    "map_result = mapped_rdd.collect()\n",
    "print(\"RDD in Upper case :\",map_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adbb3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD with Experience of 7 years : [('Raman', 7)]\n"
     ]
    }
   ],
   "source": [
    "# filter Transformation : filter records based on any condition\n",
    "filtered_rdd = employees_rdd.filter(lambda x:x[1] == 7)\n",
    "\n",
    "filtered_result = filtered_rdd.collect()\n",
    "print(\"RDD with Experience of 7 years :\", filtered_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a7e3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ajay', 8), ('Raman', 10), ('Pratap', 5), ('Mohan', 6)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReduceBy Key : Calculate the total experience for each name\n",
    "reduced_rdd = employees_rdd.reduceByKey(lambda x,y: x + y)\n",
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f47e685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RDD in Ascending Order : [('Raman', 3), ('Pratap', 5), ('Mohan', 6), ('Raman', 7), ('Ajay', 8)]\n",
      "The RDD in Descending Order : [('Ajay', 8), ('Raman', 7), ('Mohan', 6), ('Pratap', 5), ('Raman', 3)]\n"
     ]
    }
   ],
   "source": [
    "# sortBy Transformation : This returns the data arranged in ascending or descending order\n",
    "sorted_rdd_asc = employees_rdd.sortBy(lambda x: x[1], ascending = True)\n",
    "print(\"The RDD in Ascending Order :\",sorted_rdd_asc.collect())\n",
    "\n",
    "sorted_rdd_desc = employees_rdd.sortBy(lambda x: x[1], ascending = False)\n",
    "print(\"The RDD in Descending Order :\",sorted_rdd_desc.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739fc14",
   "metadata": {},
   "source": [
    "# DataFrames - Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59cf642",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d47241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rdd = rdd.flatMap(lambda line: line.split(\" \"))\\\n",
    ".map(lambda word: (word, 1))\\\n",
    ".reduceByKey(lambda a, b: a+b)\\\n",
    ".sortBy(lambda x: x[1], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58a8632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 12),\n",
       " ('a', 7),\n",
       " ('of', 7),\n",
       " ('in', 5),\n",
       " ('distributed', 5),\n",
       " ('Spark', 4),\n",
       " ('is', 3),\n",
       " ('API', 3),\n",
       " ('as', 3),\n",
       " ('on', 3),\n",
       " ('Dataset', 3),\n",
       " ('RDD', 3),\n",
       " ('its', 2),\n",
       " ('data', 2),\n",
       " ('cluster', 2),\n",
       " ('that', 2),\n",
       " ('The', 2),\n",
       " ('was', 2),\n",
       " ('API.', 2),\n",
       " ('and', 2)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35ec9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aefc90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df.selectExpr(\"explode(split(value, ' ')) as word\")\\\n",
    ".groupBy(\"word\").count().orderBy(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acdd1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "317b058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = spark.sql(\"select * from table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18c2540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|        the|   12|\n",
      "|         of|    7|\n",
      "|          a|    7|\n",
      "|         in|    5|\n",
      "|distributed|    5|\n",
      "|      Spark|    4|\n",
      "|        API|    3|\n",
      "|        RDD|    3|\n",
      "|         is|    3|\n",
      "|         on|    3|\n",
      "|    Dataset|    3|\n",
      "|         as|    3|\n",
      "|       data|    2|\n",
      "|   programs|    2|\n",
      "|        its|    2|\n",
      "|       API.|    2|\n",
      "|        and|    2|\n",
      "|  MapReduce|    2|\n",
      "|       RDDs|    2|\n",
      "|        The|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_table.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263fd5a",
   "metadata": {},
   "source": [
    "# Dataframe from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e2ba1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \".\\wholesale-trade-survey-sep-2023-quarter-csv.csv\"\n",
    "dataframe = spark.read.format(\"csv\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\", \"true\")\\\n",
    "            .load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7375c01e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_reference: string, Period: double, Data_value: double, Suppressed: string, STATUS: string, UNITS: string, Magnitude: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "867ed07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.createOrReplaceTempView(\"df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdf95d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Spark = spark.sql(\"SELECT * FROM df_table limit 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a821ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|     WTSQ.SFA1CA|1995.03|   2368.69|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|     WTSQ.SFA1CA|1995.06|   2100.44|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|     WTSQ.SFA1CA|1995.09|   2070.21|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|     WTSQ.SFA1CA|1995.12|   2284.77|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|     WTSQ.SFA1CA|1996.03|   2134.76|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf11896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_unique_STATUS = spark.sql(\"SELECT distinct(Suppressed) from df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6858aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Suppressed|\n",
      "+----------+\n",
      "|      NULL|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_unique_STATUS.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2cfba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest_Period = spark.sql(\"SELECT * from df_table order by Period desc LIMIT 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2ed9581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+-------------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|      Series_title_1|      Series_title_2|Series_title_3|     Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+-------------------+--------------+\n",
      "|     WTSQ.SFA1CS|2023.09| 11323.483|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|Seasonally adjusted|          NULL|\n",
      "|     WTSQ.SFA9CA|2023.09|  4015.207|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|        Total stocks|Current prices|         Unadjusted|          NULL|\n",
      "|     WTSQ.SFA1CT|2023.09|      NULL|      NULL|     C|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|              Trend|          NULL|\n",
      "+----------------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_highest_Period.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be04673c",
   "metadata": {},
   "source": [
    "# Renaming Columns from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "146cf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.withColumnRenamed(\"Series_reference\",\"Reference\")\\\n",
    "            .withColumnRenamed(\"Series_title_1\", \"title_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1def38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|  Reference| Period|Data_value|Suppressed|STATUS|  UNITS|Magnitude|             Subject|               Group|             title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+-----------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "|WTSQ.SFA1CA|1995.03|   2368.69|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1995.06|   2100.44|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1995.09|   2070.21|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1995.12|   2284.77|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1996.03|   2134.76|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1996.06|   2038.45|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1996.09|   2031.17|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1996.12|   2263.97|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1997.03|   1997.05|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1997.06|   2025.13|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1997.09|   2009.55|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1997.12|   2199.21|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1998.03|   2081.28|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1998.06|   2074.51|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1998.09|   1945.92|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1998.12|   2174.62|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1999.03|   2041.11|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1999.06|   2086.81|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1999.09|   2189.79|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "|WTSQ.SFA1CA|1999.12|   2285.29|      NULL|     F|Dollars|        6|Wholesale Trade S...|Industry by varia...|Basic material wh...|Sales (operating ...|Current prices|    Unadjusted|          NULL|\n",
      "+-----------+-------+----------+----------+------+-------+---------+--------------------+--------------------+--------------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
